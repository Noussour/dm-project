# üî¨ Data Mining Explorer

> **Application p√©dagogique interactive de Clustering & Classification**  
> Semestre 7 - Universit√© des Sciences et de la Technologie d'Oran

[![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-FF4B4B?logo=streamlit&logoColor=white)](https://streamlit.io)
[![Python](https://img.shields.io/badge/Python-3.11+-3776AB?logo=python&logoColor=white)](https://python.org)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-Latest-F7931E?logo=scikit-learn&logoColor=white)](https://scikit-learn.org)
[![Docker](https://img.shields.io/badge/Docker-Ready-2496ED?logo=docker&logoColor=white)](https://docker.com)

Une application web interactive permettant d'explorer, comparer et comprendre les algorithmes de **clustering** et de **classification supervis√©e** sur des jeux de donn√©es r√©els ou personnalis√©s.

---

## üì∏ Aper√ßu de l'Application

### Pr√©traitement des Donn√©es
<p align="center">
  <img src="screenshots/preprocessing.png" alt="Pr√©traitement" width="90%"/>
</p>

### Clustering
<table>
  <tr>
    <td width="50%"><img src="screenshots/clustering_3d.png" alt="Clustering 3D"/></td>
    <td width="50%"><img src="screenshots/clustering_metrics.png" alt="M√©triques Clustering"/></td>
  </tr>
  <tr>
    <td align="center"><em>Visualisation 3D des clusters</em></td>
    <td align="center"><em>M√©triques d'√©valuation</em></td>
  </tr>
</table>

### Classification Supervis√©e
<table>
  <tr>
    <td width="50%"><img src="screenshots/classification.png" alt="Classification"/></td>
    <td width="50%"><img src="screenshots/classifiers_comparision.png" alt="Comparaison Classifieurs"/></td>
  </tr>
  <tr>
    <td align="center"><em>R√©sultats de classification</em></td>
    <td align="center"><em>Comparaison des algorithmes</em></td>
  </tr>
</table>

---

## üéØ Fonctionnalit√©s Principales

### ‚úÖ Chargement des Donn√©es
- **6 datasets pr√©d√©finis** pr√™ts √† l'emploi (IRIS, Breast Cancer, Heart Disease, etc.)
- **Upload personnalis√©** de fichiers CSV/Excel
- D√©tection automatique des valeurs manquantes
- Aper√ßu statistique (5-number summary)

### ‚úÖ Pr√©traitement Intelligent
- Suppression des outliers (IQR, Z-score)
- Gestion des valeurs manquantes (suppression, moyenne, m√©diane, mode)
- Normalisation (Min-Max, Z-score, Robust Scaler)
- Sauvegarde de multiples versions pr√©trait√©es

### ‚úÖ Clustering Non-Supervis√©
- 5 algorithmes : K-Means, K-Medoids, DBSCAN, AGNES, DIANA
- D√©tection automatique des meilleurs param√®tres
- M√©triques : Silhouette, Calinski-Harabasz, Davies-Bouldin

### ‚úÖ Classification Supervis√©e
- 4 algorithmes : k-NN, Naive Bayes, C4.5, SVM
- √âvaluation k de 1 √† 10 pour k-NN
- M√©triques : Pr√©cision, Rappel, F-mesure, Matrice de confusion

### ‚úÖ Visualisations Interactives
- Scatter plots 2D/3D avec Plotly
- Dendrogrammes pour clustering hi√©rarchique
- Courbes Elbow et Silhouette
- Graphiques k-distance pour DBSCAN

### ‚úÖ Validation Intelligente
- D√©tection des cas impossibles (donn√©es continues pour classification)
- Alertes pour valeurs manquantes
- Contraintes d'algorithmes respect√©es

---

## üó∫Ô∏è Architecture de l'Application

```mermaid
flowchart TB
    subgraph USER["üë§ Utilisateur"]
        Upload["üì§ Upload Dataset"]
        Predefined["üìÅ Dataset Pr√©d√©fini"]
    end

    subgraph APP["üî¨ Application Streamlit"]
        subgraph LOAD["üìÇ Chargement"]
            DataLoader["data_loader.py"]
            Validation["Validation"]
        end

        subgraph PREPROCESS["‚öôÔ∏è Pr√©traitement"]
            Outliers["Outliers Detection"]
            Missing["Missing Values"]
            Normalize["Normalization"]
        end

        subgraph CLUSTER["üîµ Clustering"]
            KMeans["K-Means"]
            KMedoids["K-Medoids"]
            DBSCAN["DBSCAN"]
            AGNES["AGNES"]
            DIANA["DIANA"]
        end

        subgraph CLASSIFY["üü¢ Classification"]
            KNN["k-NN"]
            NaiveBayes["Naive Bayes"]
            C45["C4.5"]
            SVM["SVM"]
        end

        subgraph VIZ["üìä Visualisation"]
            Scatter2D["2D Scatter"]
            Scatter3D["3D Scatter"]
            Dendro["Dendrogram"]
            Charts["Metrics Charts"]
        end
    end

    subgraph OUTPUT["üìà R√©sultats"]
        Metrics["M√©triques"]
        Compare["Comparaison"]
        Export["Export"]
    end

    Upload --> DataLoader
    Predefined --> DataLoader
    DataLoader --> Validation
    Validation --> PREPROCESS
    PREPROCESS --> CLUSTER
    PREPROCESS --> CLASSIFY
    CLUSTER --> VIZ
    CLASSIFY --> VIZ
    VIZ --> Metrics
    Metrics --> Compare
```

---

## üìÅ Structure du Projet

```
DM-Project/
‚îú‚îÄ‚îÄ app.py                 # Point d'entr√©e principal
‚îú‚îÄ‚îÄ requirements.txt       # D√©pendances Python
‚îú‚îÄ‚îÄ Dockerfile            # Configuration Docker
‚îú‚îÄ‚îÄ docker-compose.yaml   # Orchestration Docker
‚îÇ
‚îú‚îÄ‚îÄ config/               # Configuration
‚îÇ   ‚îú‚îÄ‚îÄ constants.py      # Constantes & datasets pr√©d√©finis
‚îÇ   ‚îî‚îÄ‚îÄ settings.py       # Param√®tres application
‚îÇ
‚îú‚îÄ‚îÄ utils/                # Utilitaires
‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py    # Chargement & validation donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.py  # Transformations donn√©es
‚îÇ   ‚îî‚îÄ‚îÄ metrics.py        # Calculs m√©triques
‚îÇ
‚îú‚îÄ‚îÄ clustering/           # Algorithmes de clustering
‚îÇ   ‚îú‚îÄ‚îÄ kmeans.py         # K-Means
‚îÇ   ‚îú‚îÄ‚îÄ kmedoids.py       # K-Medoids
‚îÇ   ‚îú‚îÄ‚îÄ dbscan.py         # DBSCAN
‚îÇ   ‚îú‚îÄ‚îÄ agnes.py          # AGNES (hi√©rarchique ‚Üë)
‚îÇ   ‚îî‚îÄ‚îÄ diana.py          # DIANA (hi√©rarchique ‚Üì)
‚îÇ
‚îú‚îÄ‚îÄ classification/       # Algorithmes de classification
‚îÇ   ‚îú‚îÄ‚îÄ knn.py            # k-NN
‚îÇ   ‚îú‚îÄ‚îÄ naive_bayes.py    # Naive Bayes
‚îÇ   ‚îú‚îÄ‚îÄ decision_tree.py  # C4.5
‚îÇ   ‚îî‚îÄ‚îÄ svm.py            # SVM
‚îÇ
‚îú‚îÄ‚îÄ components/           # Composants UI Streamlit
‚îÇ   ‚îú‚îÄ‚îÄ sidebar.py        # Sidebar clustering
‚îÇ   ‚îú‚îÄ‚îÄ classification_sidebar.py
‚îÇ   ‚îú‚îÄ‚îÄ tabs.py           # Onglets clustering
‚îÇ   ‚îî‚îÄ‚îÄ classification_tabs.py
‚îÇ
‚îú‚îÄ‚îÄ visualization/        # Visualisations
‚îÇ   ‚îú‚îÄ‚îÄ plots.py          # Graphiques Plotly
‚îÇ   ‚îî‚îÄ‚îÄ colors.py         # Palettes couleurs
‚îÇ
‚îî‚îÄ‚îÄ datasets/             # Datasets pr√©d√©finis
    ‚îú‚îÄ‚îÄ IRIS 1.csv
    ‚îú‚îÄ‚îÄ breast.csv
    ‚îú‚îÄ‚îÄ heart.csv
    ‚îî‚îÄ‚îÄ ...
```

---

## ü§ñ Algorithmes Disponibles

### üîµ Clustering (Non-Supervis√©)

| Algorithme | Type | Description | Param√®tres |
|:-----------|:-----|:------------|:-----------|
| **K-Means** | Partitionnement | Minimise l'inertie intra-cluster via centro√Ødes | `n_clusters`, `init` |
| **K-Medoids** | Partitionnement | Utilise des m√©do√Ødes (robuste aux outliers) | `n_clusters`, `metric` |
| **DBSCAN** | Densit√© | D√©tecte clusters de forme arbitraire + bruit | `eps`, `min_samples` |
| **AGNES** | Hi√©rarchique ‚Üë | Agglom√©ration ascendante (bottom-up) | `n_clusters`, `linkage` |
| **DIANA** | Hi√©rarchique ‚Üì | Division descendante (top-down) | `n_clusters`, `metric` |

### üü¢ Classification (Supervis√©e)

| Algorithme | Type | Description | Param√®tres |
|:-----------|:-----|:------------|:-----------|
| **k-NN** | Instance-based | Vote majoritaire des k plus proches voisins | `k`, `metric`, `weights` |
| **Naive Bayes** | Probabiliste | Classifieur bay√©sien avec ind√©pendance na√Øve | `type` (gaussian/multinomial/bernoulli) |
| **C4.5** | Arbre de d√©cision | Gain d'information / ratio de gain | `criterion`, `max_depth`, `min_samples` |
| **SVM** | Marge maximale | Hyperplan s√©parateur optimal | `kernel`, `C`, `gamma` |

---

## üìä Datasets Pr√©d√©finis

| Dataset | Instances | Features | Classes | Valeurs Manquantes | Recommand√© Pour |
|:--------|:---------:|:--------:|:-------:|:------------------:|:----------------|
| üå∏ **IRIS** | 150 | 4 | 3 | ‚ùå Non | Clustering, Classification |
| üéóÔ∏è **Breast Cancer** | 569 | 18 | 2 | ‚ùå Non | Clustering, Classification |
| ‚ù§Ô∏è **Heart Disease** | 303 | 13 | 2 | ‚ùå Non | Clustering, Classification |
| ü¶† **Ecoli** | 336 | 7 | 8 | ‚ùå Non | Clustering, Classification |
| üè• **Hepatitis** | 155 | 19 | 2 | ‚ö†Ô∏è Oui | Classification (apr√®s pr√©traitement) |
| üê¥ **Horse Colic** | 300 | 27 | 3 | ‚ö†Ô∏è Oui | Classification (apr√®s pr√©traitement) |

---

## üìà M√©triques d'√âvaluation

### Clustering

| M√©trique | Plage | Optimal | Interpr√©tation |
|:---------|:-----:|:-------:|:---------------|
| **Silhouette Score** | [-1, 1] | ‚Üí 1 | Mesure coh√©sion vs s√©paration |
| **Calinski-Harabasz** | [0, +‚àû) | ‚Üë Haut | Ratio variance inter/intra cluster |
| **Davies-Bouldin** | [0, +‚àû) | ‚Üì Bas | Similarit√© moyenne entre clusters |
| **Inertie (WCSS)** | [0, +‚àû) | ‚Üì Bas | Somme des distances¬≤ intra-cluster |

### Classification

| M√©trique | Formule | Interpr√©tation |
|:---------|:--------|:---------------|
| **Accuracy** | (TP+TN) / Total | Taux de pr√©dictions correctes |
| **Pr√©cision** | TP / (TP+FP) | Fiabilit√© des pr√©dictions positives |
| **Rappel** | TP / (TP+FN) | Capacit√© √† trouver tous les positifs |
| **F1-Score** | 2√ó(P√óR)/(P+R) | Moyenne harmonique pr√©cision/rappel |

---

## üöÄ Installation

### Pr√©requis

- **Python 3.11+**
- **pip** (gestionnaire de paquets Python)

### Installation Locale

```bash
# 1. Cloner le repository
git clone https://github.com/Noussour/dm-project.git
cd dm-project

# 2. Cr√©er un environnement virtuel (recommand√©)
python -m venv .venv

# Activer l'environnement
source .venv/bin/activate      # macOS/Linux
# .venv\Scripts\activate       # Windows

# 3. Installer les d√©pendances
pip install -r requirements.txt

# 4. Lancer l'application
streamlit run app.py
```

üåê **Acc√®s** : http://localhost:8501

### üê≥ Installation Docker

```bash
# Option 1: Docker Compose (recommand√©)
docker-compose up --build

# Option 2: Docker direct
docker build -t dm-explorer .
docker run -p 8501:8501 dm-explorer
```

---

## üíª Guide d'Utilisation

### √âtape 1 : Charger les Donn√©es

1. **Dataset pr√©d√©fini** : S√©lectionnez dans le menu d√©roulant et cliquez "Charger"
2. **Upload** : Glissez-d√©posez un fichier CSV/Excel

### √âtape 2 : Pr√©traitement (si n√©cessaire)

1. Naviguez vers l'onglet **Pr√©traitement**
2. Configurez :
   - **Outliers** : IQR ou Z-score
   - **Valeurs manquantes** : Suppression, moyenne, m√©diane, mode
   - **Normalisation** : Min-Max, Z-score, Robust
3. Cliquez **Ex√©cuter le pipeline**

### √âtape 3 : Clustering

1. Naviguez vers **Clustering**
2. S√©lectionnez l'algorithme (K-Means, DBSCAN, etc.)
3. Ajustez les param√®tres ou cliquez **Meilleurs params**
4. Cliquez **Ex√©cuter**
5. Explorez les onglets : Visualisation, M√©triques, Graphiques

### √âtape 4 : Classification

1. Naviguez vers **Classification**
2. S√©lectionnez la **variable cible** (classes)
3. Configurez le **split train/test** (80/20 par d√©faut)
4. Choisissez l'algorithme
5. Cliquez **Classifier** ou **Comparer tous**

---

## ‚ö†Ô∏è Validation et Contraintes

L'application d√©tecte automatiquement les cas probl√©matiques :

| Situation | Action |
|:----------|:-------|
| Valeurs manquantes + Clustering | ‚ùå Bloque l'ex√©cution |
| Variable cible continue | ‚ùå Erreur avec suggestion |
| Trop peu d'√©chantillons | ‚ö†Ô∏è Avertissement |
| Classes d√©s√©quilibr√©es | ‚ö†Ô∏è Avertissement |
| n_clusters ‚â• n_samples | ‚ùå Erreur de param√®tre |
| Dendrogramme > 1000 points | ‚ö†Ô∏è D√©sactiv√© |

---

## üõ†Ô∏è Technologies

| Technologie | Version | R√¥le |
|:------------|:-------:|:-----|
| **Streamlit** | 1.28+ | Framework UI web |
| **scikit-learn** | Latest | Algorithmes ML |
| **Plotly** | Latest | Visualisations interactives |
| **Pandas** | Latest | Manipulation donn√©es |
| **NumPy** | Latest | Calculs num√©riques |
| **SciPy** | Latest | Clustering hi√©rarchique |
| **Matplotlib/Seaborn** | Latest | Graphiques statiques |

---

## üìù Notes P√©dagogiques

Cette application a √©t√© d√©velopp√©e pour permettre aux √©tudiants de :

1. **Comprendre** les diff√©rences fondamentales entre algorithmes
2. **Visualiser** l'impact des hyperparam√®tres sur les r√©sultats
3. **Comparer** objectivement les performances via m√©triques standardis√©es
4. **Explorer** le pr√©traitement et son importance sur la qualit√© des mod√®les
5. **Apprendre** les bonnes pratiques (validation, split train/test, etc.)