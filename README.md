# ğŸ”¬ Comparateur d'Algorithmes de Clustering & Classification

> Application pÃ©dagogique de **Data Mining** (Semestre 7)

Une application web interactive construite avec **Streamlit** permettant de comparer diffÃ©rents algorithmes de clustering et de classification sur des jeux de donnÃ©es personnalisÃ©s.

---

## ğŸ“‹ Table des MatiÃ¨res

- [FonctionnalitÃ©s](#-fonctionnalitÃ©s)
- [Algorithmes SupportÃ©s](#-algorithmes-supportÃ©s)
- [Architecture du Projet](#-architecture-du-projet)
- [Installation](#-installation)
- [Utilisation](#-utilisation)
- [MÃ©triques d'Ã‰valuation](#-mÃ©triques-dÃ©valuation)
- [Docker](#-docker)
- [Technologies UtilisÃ©es](#-technologies-utilisÃ©es)

---

## âœ¨ FonctionnalitÃ©s

- **Chargement de donnÃ©es** : Upload de fichiers CSV/Excel
- **PrÃ©traitement des donnÃ©es** : Gestion des valeurs manquantes, outliers, normalisation
- **SÃ©lection de features** : Choix interactif des colonnes numÃ©riques
- **Clustering** : K-Means, K-Medoids, DBSCAN, AGNES, DIANA
- **Classification** : k-NN, Naive Bayes, C4.5, SVM
- **Visualisation 2D/3D** : Graphiques interactifs Plotly
- **MÃ©triques dÃ©taillÃ©es** : Scores Silhouette, Calinski-Harabasz, Davies-Bouldin (clustering), PrÃ©cision, Rappel, F-mesure (classification)
- **Comparaison** : Comparer tous les algorithmes en un clic

---

## ğŸ¤– Algorithmes SupportÃ©s

### Clustering

| Algorithme | Description | ParamÃ¨tres |
|------------|-------------|------------|
| **K-Means** | Partitionnement en k clusters basÃ© sur les centroÃ¯des | `n_clusters`, `init` |
| **K-Medoids** | Partitionnement robuste aux outliers (PAM) | `n_clusters`, `metric` |
| **DBSCAN** | Clustering basÃ© sur la densitÃ©, dÃ©tecte le bruit | `eps`, `min_samples` |
| **AGNES** | Agglomerative Nesting (approche ascendante) | `n_clusters`, `linkage` |
| **DIANA** | Divisive Analysis (approche descendante) | `n_clusters`, `metric` |

### Classification

| Algorithme | Description | ParamÃ¨tres |
|------------|-------------|------------|
| **k-NN** | k plus proches voisins | `k`, `metric`, `weights` |
| **Naive Bayes** | Classifieur bayÃ©sien naÃ¯f | `type` (gaussian, multinomial) |
| **C4.5** | Arbre de dÃ©cision (gain d'information) | `criterion`, `max_depth` |
| **SVM** | Machine Ã  vecteurs de support | `kernel`, `C`, `gamma` |

---

## ğŸ“ Architecture du Projet

```
TP4/
â”œâ”€â”€ app.py                  # Point d'entrÃ©e principal
â”œâ”€â”€ requirements.txt        # DÃ©pendances Python
â”œâ”€â”€ Dockerfile              # Image Docker
â”œâ”€â”€ docker-compose.yaml     # Orchestration Docker
â”‚
â”œâ”€â”€ config/                 # Configuration et constantes
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ settings.py         # Configuration Streamlit
â”‚   â””â”€â”€ constants.py        # Couleurs, algorithmes supportÃ©s, limites
â”‚
â”œâ”€â”€ utils/                  # Fonctions utilitaires
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_loader.py      # Chargement/validation des donnÃ©es
â”‚   â”œâ”€â”€ preprocessing.py    # Pipeline de prÃ©traitement
â”‚   â””â”€â”€ metrics.py          # MÃ©triques de clustering
â”‚
â”œâ”€â”€ clustering/             # ImplÃ©mentations des algorithmes de clustering
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ algorithms.py       # Orchestrateur principal
â”‚   â”œâ”€â”€ kmeans.py           # K-Means
â”‚   â”œâ”€â”€ kmedoids.py         # K-Medoids (PAM)
â”‚   â”œâ”€â”€ dbscan.py           # DBSCAN
â”‚   â”œâ”€â”€ agnes.py            # AGNES
â”‚   â””â”€â”€ diana.py            # DIANA
â”‚
â”œâ”€â”€ classification/         # ImplÃ©mentations des algorithmes de classification
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ algorithms.py       # Orchestrateur principal
â”‚   â”œâ”€â”€ knn.py              # k-NN
â”‚   â”œâ”€â”€ naive_bayes.py      # Naive Bayes
â”‚   â”œâ”€â”€ decision_tree.py    # C4.5
â”‚   â”œâ”€â”€ svm.py              # SVM
â”‚   â””â”€â”€ metrics.py          # MÃ©triques de classification
â”‚
â”œâ”€â”€ visualization/          # Visualisation des rÃ©sultats
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ plots.py            # Graphiques
â”‚   â””â”€â”€ colors.py           # Gestion palette de couleurs
â”‚
â””â”€â”€ components/             # Composants UI Streamlit
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ sidebar.py          # Sidebar clustering
    â”œâ”€â”€ classification_sidebar.py  # Sidebar classification
    â”œâ”€â”€ tabs.py             # Onglets clustering
    â””â”€â”€ classification_tabs.py  # Onglets classification
```

---

## ğŸš€ Installation

### PrÃ©requis

- Python 3.11+
- pip

### Installation locale

```bash
# 1. Cloner ou accÃ©der au rÃ©pertoire
cd TP4

# 2. CrÃ©er un environnement virtuel (recommandÃ©)
python -m venv .venv
source .venv/bin/activate  # macOS/Linux
# .venv\Scripts\activate   # Windows

# 3. Installer les dÃ©pendances
pip install -r requirements.txt

# 4. Lancer l'application
streamlit run app.py
```

L'application sera accessible Ã  l'adresse : **http://localhost:8501**

---

## ğŸ’» Utilisation

### 1. Charger les donnÃ©es

Glisser-dÃ©poser un fichier CSV ou Excel dans la zone de tÃ©lÃ©chargement.

### 2. PrÃ©traitement

Utilisez l'onglet **PrÃ©traitement** pour :
- Supprimer les outliers (mÃ©thode IQR ou Z-score)
- GÃ©rer les valeurs manquantes (suppression, moyenne, mÃ©diane)
- Normaliser les donnÃ©es (Min-Max, Z-score)

### 3. Clustering

1. SÃ©lectionner l'algorithme (K-Means, K-Medoids, DBSCAN, AGNES, DIANA)
2. Ajuster les paramÃ¨tres spÃ©cifiques
3. Cliquer sur **"ExÃ©cuter"** ou **"Meilleurs params"**

### 4. Classification

1. SÃ©lectionner la variable cible (classe)
2. Configurer le partitionnement (80% apprentissage, 20% test)
3. Choisir l'algorithme (k-NN, Naive Bayes, C4.5, SVM)
4. Cliquer sur **"Classifier"** ou **"Comparer tous"**

---

## ğŸ“Š MÃ©triques d'Ã‰valuation

### Clustering

| MÃ©trique | Plage | InterprÃ©tation |
|----------|-------|----------------|
| **Silhouette Score** | [-1, 1] | Plus Ã©levÃ© = meilleure sÃ©paration entre clusters |
| **Calinski-Harabasz** | [0, +âˆ) | Plus Ã©levÃ© = clusters plus denses et bien sÃ©parÃ©s |
| **Davies-Bouldin** | [0, +âˆ) | Plus faible = meilleure distinction entre clusters |

### Classification

| MÃ©trique | Description |
|----------|-------------|
| **PrÃ©cision** | TP / (TP + FP) |
| **Rappel** | TP / (TP + FN) |
| **F-mesure** | 2 Ã— (P Ã— R) / (P + R) |
| **Matrice de Confusion** | TP, TN, FP, FN |

---

## ğŸ³ Docker

### Lancer avec Docker Compose

```bash
# Construire et lancer
docker-compose up --build

# En mode dÃ©tachÃ©
docker-compose up -d --build
```

### Lancer avec Docker directement

```bash
# Construire l'image
docker build -t tp4-clustering .

# Lancer le conteneur
docker run -p 8501:8501 tp4-clustering
```

AccÃ©der Ã  l'application : **http://localhost:8501**

---

## ğŸ›  Technologies UtilisÃ©es

| Technologie | RÃ´le |
|-------------|------|
| **Streamlit** | Framework web interactif |
| **scikit-learn** | Algorithmes de clustering, classification et mÃ©triques |
| **Plotly** | Visualisations interactives 2D/3D |
| **Matplotlib/Seaborn** | Graphiques et palettes de couleurs |
| **Pandas/NumPy** | Manipulation des donnÃ©es |
| **SciPy** | Clustering hiÃ©rarchique (linkage) |

---

## ğŸ“ Notes PÃ©dagogiques

Cette application a Ã©tÃ© dÃ©veloppÃ©e dans le cadre du **TP4 de Data Mining** pour permettre aux Ã©tudiants de :

1. **Comprendre** les diffÃ©rences entre algorithmes de clustering
2. **Visualiser** l'impact des paramÃ¨tres sur les rÃ©sultats
3. **Comparer** objectivement les algorithmes via des mÃ©triques standardisÃ©es
4. **Explorer** diffÃ©rents types de donnÃ©es (rÃ©elles et synthÃ©tiques)